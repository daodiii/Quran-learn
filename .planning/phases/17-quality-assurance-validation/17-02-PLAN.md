---
phase: 17-quality-assurance-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/validate-glossary-links.ts
  - scripts/validate-readability.ts
autonomous: true

must_haves:
  truths:
    - "Glossary link validator detects broken cross-references between lessons and resource pages"
    - "Glossary link validator checks internal lesson-to-lesson links resolve to actual files"
    - "Readability validator measures difficulty metrics per level and flags regressions"
    - "Readability validator confirms Arabic density increases from Level 1 to Level 5"
  artifacts:
    - path: "scripts/validate-glossary-links.ts"
      provides: "Cross-reference validation between lessons and glossary/resource pages"
      exports: ["validateGlossaryLinks"]
    - path: "scripts/validate-readability.ts"
      provides: "Difficulty progression analysis across 5 levels"
      exports: ["validateReadability"]
  key_links:
    - from: "scripts/validate-glossary-links.ts"
      to: "src/content/resources/glossary.mdx"
      via: "reads glossary to extract valid anchor IDs"
      pattern: "glossary\\.mdx"
    - from: "scripts/validate-readability.ts"
      to: "src/content/lessons/"
      via: "reads all lesson files to calculate metrics per level"
      pattern: "src/content/lessons"
---

<objective>
Create two new validators: a glossary link checker that verifies all cross-references between lessons and resource pages resolve correctly, and a readability progression checker that confirms difficulty increases appropriately from Level 1 to Level 5.

Purpose: Success criteria #4 (readability/difficulty progression) and #5 (glossary links) require validators that don't exist yet. These catch broken navigation and difficulty regressions.
Output: New validate-glossary-links.ts, new validate-readability.ts
</objective>

<execution_context>
@/Users/daodilyas/.claude/get-shit-done/workflows/execute-plan.md
@/Users/daodilyas/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/17-quality-assurance-validation/17-RESEARCH.md

@scripts/validate-content.ts
@src/content/resources/glossary.mdx
@docs/CURRICULUM_MAP.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create glossary link validator</name>
  <files>scripts/validate-glossary-links.ts</files>
  <action>
Create `scripts/validate-glossary-links.ts` that validates all cross-references in lesson and resource files. Use only Node.js built-ins (fs, path) - no external packages.

**Structure:**
```typescript
import { readFileSync, readdirSync, statSync, existsSync } from 'fs';
import { join, basename, dirname } from 'path';
import { fileURLToPath } from 'url';
```

**Export interface:**
```typescript
export interface LinkIssue {
  file: string;
  line: number;
  linkText: string;
  href: string;
  reason: string;
  severity: 'error' | 'warning';
}

export function validateGlossaryLinks(): LinkIssue[]
```

**Implementation requirements:**

1. **Find all content files** - Scan `src/content/lessons/` (all levels, skip `_` prefixed) and `src/content/resources/` for .mdx files

2. **Extract markdown links** from each file - Pattern: `[text](href)` - Extract text, href, and line number for each link

3. **Check 1: Glossary anchor validation** - For links pointing to `/resources/glossary` (or relative paths to glossary):
   - Load `src/content/resources/glossary.mdx` once
   - Extract all heading anchors (## and ### headings, convert to slug: lowercase, spaces to hyphens, strip non-word chars except hyphens)
   - For each link with an anchor (e.g., `/resources/glossary#raf`), verify the anchor exists in the glossary
   - Flag missing anchors as errors

4. **Check 2: Internal lesson links** - For links pointing to `/learn/` paths or relative lesson paths:
   - Resolve the path to a lesson file in `src/content/lessons/`
   - Check if the target file exists on disk
   - Flag non-existent targets as errors

5. **Check 3: Resource page links** - For links pointing to `/resources/` paths:
   - Verify the target resource file exists in `src/content/resources/`
   - Flag missing resources as errors

6. **Ignore external links** (http/https URLs) - out of scope for this validator

**CLI section** at bottom (same pattern as other validators):
- Accept optional file path argument for single-file mode
- Default behavior: scan all content files
- Print results grouped by file, exit with code 1 if errors found

Target under 200 lines. Keep simple and maintainable.
  </action>
  <verify>
Run the glossary link validator:
```bash
npx tsx scripts/validate-glossary-links.ts 2>&1 | tail -15
```
Should produce output showing link validation results (broken links or all-clear).
  </verify>
  <done>
- scripts/validate-glossary-links.ts exists with validateGlossaryLinks() export
- Validates glossary anchor references
- Validates internal lesson cross-references
- Validates resource page links
- Uses Node.js built-ins only
- CLI usage section present
  </done>
</task>

<task type="auto">
  <name>Task 2: Create readability and difficulty progression validator</name>
  <files>scripts/validate-readability.ts</files>
  <action>
Create `scripts/validate-readability.ts` that measures content difficulty metrics per level and validates proper progression from Level 1 (easiest) to Level 5 (hardest). Use only Node.js built-ins - no external readability scoring libraries. Implement simple but effective metrics.

**Structure:**
```typescript
import { readFileSync, readdirSync, statSync } from 'fs';
import { join, basename } from 'path';
import { fileURLToPath } from 'url';
```

**Export interface:**
```typescript
export interface LevelMetrics {
  level: number;
  lessonCount: number;
  avgWordCount: number;
  avgSentenceLength: number;
  avgArabicDensity: number;
  avgUniqueTerms: number;
  avgExerciseCount: number;
}

export interface ReadabilityIssue {
  type: 'difficulty_regression' | 'arabic_density_regression' | 'exercise_count_low';
  severity: 'error' | 'warning';
  message: string;
  level: number;
}

export function validateReadability(): { metrics: LevelMetrics[]; issues: ReadabilityIssue[] }
```

**Implementation requirements:**

1. **Load all lesson files** grouped by level (from directory: level-1 through level-5)

2. **Calculate per-lesson metrics** (English-only text, excluding frontmatter, code blocks, import lines, and lines that are primarily Arabic):
   - **Word count** - Total English words in lesson
   - **Average sentence length** - Words per sentence (split on `.`, `!`, `?`)
   - **Arabic density** - Ratio of Arabic characters to total characters
   - **Unique Arabic terms** - Count of distinct Arabic word forms ([\u0600-\u06FF]+ patterns)
   - **Exercise count** - Count occurrences of `<ExerciseBox` components

3. **Aggregate per-level averages** - Average each metric across all lessons in a level

4. **Progression checks:**
   - **Difficulty regression:** If average word count + average sentence length + unique terms for Level N is LESS than Level N-1 (use a combined weighted score), flag as warning
   - **Arabic density regression:** If average Arabic density for Level N is less than Level N-1, flag as warning (Arabic usage should increase as learners advance)
   - **Exercise count:** If any lesson has fewer than 3 ExerciseBox components, flag as warning (LSSN-10 requires 3-4 exercises per lesson)

5. **Output:** Print a summary table showing per-level metrics, then list any progression issues

**CLI section** at bottom:
- Default: analyze all lessons and print metrics table + issues
- Exit with code 0 (warnings only, since difficulty is advisory not blocking)

Target under 200 lines. Use simple, transparent calculations. No external dependencies.
  </action>
  <verify>
Run the readability validator:
```bash
npx tsx scripts/validate-readability.ts 2>&1 | tail -20
```
Should produce a per-level metrics table and list any progression warnings.
  </verify>
  <done>
- scripts/validate-readability.ts exists with validateReadability() export
- Calculates word count, sentence length, Arabic density, unique terms, exercise count per level
- Flags difficulty regressions between adjacent levels
- Flags Arabic density regressions
- Flags lessons with fewer than 3 exercises
- Uses Node.js built-ins only
- CLI usage section present with metrics table output
  </done>
</task>

</tasks>

<verification>
1. `npx tsx scripts/validate-glossary-links.ts` runs and produces link validation output
2. `npx tsx scripts/validate-readability.ts` runs and produces per-level metrics table
3. Both scripts use Node.js built-ins only (no external dependencies)
4. Both scripts have proper TypeScript interfaces and exported functions
5. Both scripts follow the project's existing validator patterns (CLI usage, issue reporting)
</verification>

<success_criteria>
- Glossary link validator catches broken anchors and non-existent internal links
- Readability validator produces measurable difficulty metrics per level
- Both validators can be invoked standalone and imported by the report generator
- No external package installations required
</success_criteria>

<output>
After completion, create `.planning/phases/17-quality-assurance-validation/17-02-SUMMARY.md`
</output>
